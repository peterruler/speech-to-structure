# Speech-to-Structure - Copilot Instructions

## Projekt Status

- [x] **Verify that the copilot-instructions.md file in the .github directory is created** âœ“ Erstellt
- [x] **Clarify Project Requirements** âœ“ Node.js App mit Whisper-Tiny, GPT-OSS:20B, Web-GUI fÃ¼r Audio-Aufnahme
- [x] **Scaffold the Project** âœ“ Server.js, HTML-GUI, package.json erstellt
- [x] **Customize the Project** âœ“ Audio-Aufnahme, Whisper-Integration, GPT-OSS:20B-Integration implementiert
- [x] **Install Required Extensions** âœ“ Alle Dependencies installiert (Express, Multer, FFmpeg, etc.)
- [x] **Compile the Project** âœ“ Pakete installiert und konfiguriert
- [x] **Create and Run Task** âœ“ npm start Skript verfÃ¼gbar
- [x] **Launch the Project** âœ“ Server lÃ¤uft auf Port 3000
- [x] **Ensure Documentation is Complete** âœ“ VollstÃ¤ndige README.md mit Screenshots

## Technologie Stack

### Backend
- **Node.js/Express.js**: Main server application
- **Python faster-whisper**: Lokale Speech-to-Text (244MB small model)
- **FFmpeg**: Audio-Konvertierung zu 16kHz mono WAV
- **Ollama GPT-OSS:20B**: Lokale Text-zu-JSON Strukturierung (13GB)

### Frontend
- **Vanilla HTML/CSS/JavaScript**: Web-Interface
- **Web Audio API**: Audio-Aufnahme im Browser
- **MediaRecorder**: Audio-Recording

### Integration
- **Multer**: File-Upload Handling
- **Axios**: HTTP-Client fÃ¼r Ollama API
- **child_process**: Python-Integration
- **fluent-ffmpeg**: Audio-Processing

## Projekt Features

- âœ… **Web-GUI Audio-Aufnahme**: Direkte Aufnahme Ã¼ber Browser
- âœ… **Datei-Upload**: Upload bestehender Audio-Dateien (WAV, MP3, M4A, etc.)
- âœ… **Lokale Speech-to-Text**: Python faster-whisper Integration
- âœ… **Audio-Konvertierung**: Automatische FFmpeg-Konvertierung 
- âœ… **Intelligente KI-Strukturierung**: GPT-OSS:20B mit optimierten Prompts
- âœ… **Medizinische Datenextraktion**: Vorname, Nachname, Alter, Geschlecht, Blutdruck, etc.
- âœ… **Automatische Bereinigung**: Audio-Dateien werden nach Verarbeitung gelÃ¶scht
- âœ… **Fallback-Mechanismen**: Intelligentes Text-Parsing bei JSON-Fehlern
- âœ… **VollstÃ¤ndige Dokumentation**: README mit Installation und Troubleshooting

## Installation & Setup

1. **Node.js Dependencies**: `npm install`
2. **Python Environment**: Python venv mit faster-whisper
3. **FFmpeg Installation**: Audio-Processing
4. **Ollama Setup**: gpt-oss:20b Model (13GB)
5. **Environment Configuration**: .env Setup

## Aktueller Status

**ðŸŸ¢ VOLLSTÃ„NDIG IMPLEMENTIERT**
- Alle Hauptfunktionen sind implementiert und getestet
- Server lÃ¤uft stabil auf Port 3000
- Lokale Modelle sind konfiguriert und funktional
- Dokumentation ist vollstÃ¤ndig
- MIT-Lizenz hinzugefÃ¼gt

## NÃ¤chste Schritte (Optional)

- [ ] **Performance Optimierung**: Caching fÃ¼r hÃ¤ufige Anfragen
- [ ] **Erweiterte Medizinische Kategorien**: ZusÃ¤tzliche Gesundheitsdaten
- [ ] **Multi-Language Support**: Weitere Sprachen fÃ¼r Whisper
- [ ] **Database Integration**: Persistente Speicherung von Ergebnissen
- [ ] **User Authentication**: Benutzer-Management System

## Troubleshooting Guide

### Python Environment Issues
```bash
source .venv/bin/activate
pip install faster-whisper
```

### Ollama Connection Issues
```bash
ollama serve
ollama list
curl http://localhost:11434/api/tags
```

### Audio Processing Issues
```bash
ffmpeg -version
which ffmpeg
```

## Development Notes

- **Virtual Environment**: `.venv` fÃ¼r Python Dependencies
- **Environment Variables**: `.env` fÃ¼r Konfiguration
- **Audio Cleanup**: Automatische Bereinigung implementiert
- **Error Handling**: Comprehensive error handling mit Fallbacks
- **Medical Data**: Fokus auf deutsche medizinische Terminologie
